import telebot
from telebot import types
from torchvision import models
import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from types import SimpleNamespace
import torch
import torchvision
import torch.nn as nn  # Ð·Ð´ÐµÑÑŒ Ð»ÐµÐ¶Ð°Ñ‚ Ð²ÑÐµ ÑÐ»Ð¾Ð¸
import torchvision.transforms as transforms

bot = telebot.TeleBot(os.environ['TELEGRAM_TOKEN'])


config: SimpleNamespace = SimpleNamespace()  # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²Ð° Ð¸Ð¼ÐµÐ½
config.maxSize = 400  # Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð´Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
config.totalStep = 50  # Ð¾Ð±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑˆÐ°Ð³Ð¾Ð² Ð·Ð° ÑÐ¿Ð¾Ñ…Ñƒ
config.step = 5  # ÑˆÐ°Ð³
config.sampleStep = 100  # ÑˆÐ°Ð³ Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð¾Ð±Ñ€Ð°Ð·Ñ†Ð°
config.styleWeight = 1000  # Ð²ÐµÑ Ð½Ð° ÑÑ‚Ð¸Ð»ÑŒ
config.lr = .003  # ÑˆÐ°Ð³ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
config.content = 'photos\\ny.jpg'
config.style = 'photos\\Style.jpg'

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
vgg16 = torchvision.models.vgg16(
    pretrained=True).eval()  # Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð³Ð¾Ñ‚Ð¾Ð²ÑƒÑŽ vgg16 Ñ Ð¿Ñ€ÐµÐ´Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ð²ÐµÑÐ°Ð¼Ð¸, Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð² Ñ€ÐµÐ¶Ð¸Ð¼ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸

user_dict = dict()

start_markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
ready_markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
item1 = types.KeyboardButton('ðŸŽ® ÐÐ°Ñ‡Ð°Ñ‚ÑŒ')
item2 = types.KeyboardButton('ðŸ’¡ ÐžÐ±Ñ‰Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ')
item3 = types.KeyboardButton('âœ… ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾')
item4 = types.KeyboardButton('â„¹ï¸ ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾')
item5 = types.KeyboardButton('1ï¸âƒ£ Ð¡Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ñ„Ð¾Ñ‚Ð¾')
item6 = types.KeyboardButton('2ï¸âƒ£ Ð¡Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾ ÑÑ‚Ð¸Ð»Ñ')

start_markup.add(item1, item2)
ready_markup.add(item3, item4, item5, item6)


class UserInfo:
    """ÐšÐ»Ð°ÑÑ Ð´Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ðµ"""

    def __init__(self, userid: str, original_photo: bool, style_photo: bool, config):
        self.id = userid
        self.original_photo = original_photo
        self.style_photo = style_photo
        self.content = config.content
        self.style = config.style
        self.directory = f'users\\user{self.id}'


class PretrainedNet(nn.Module):
    """ÐšÐ»Ð°ÑÑ Ð´Ð»Ñ Ð¾Ð±Ð¾Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€ÐµÐ´Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ ÑÐµÑ‚Ð¸"""

    def __init__(self):
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        super(PretrainedNet, self).__init__()
        self.select = [0, 5, 7, 10, 15]  # Ñ‚Ðµ ÑÐ»Ð¾Ð¸, Ñ‡ÐµÑ€ÐµÐ· ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ Ð±ÑƒÐ´Ñƒ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ
        self.pretrainedNet = models.vgg19(pretrained=True).to(device)  # Ð¿Ð¾Ð´Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð¿Ñ€ÐµÐ´Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½ÑƒÑŽ ÑÐµÑ‚ÑŒ

    def forward(self, x):
        features = []  # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÑŽ Ð¿Ð¾ Ð¸Ð½Ð´ÐµÐºÑÐ°Ð¼, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ Ð¿Ñ€Ð¾Ð¿Ð¸ÑÐ°Ð» Ð²Ñ‹ÑˆÐµ, feature map
        output = x
        for layerIndex in range(len(self.pretrainedNet.features)):
            output = self.pretrainedNet.features[layerIndex](output)
            if layerIndex in self.select:
                features.append(output)
        return features


def load_image(image_path, transform=None, max_size=None, shape=None):
    """Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ"""
    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ
    image = Image.open(image_path)

    # Ð•ÑÐ»Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€, Ñ‚Ð¾ Ð¼ÐµÐ½ÑÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð½Ð°ÑˆÐµÐ³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    if max_size:
        scale = max_size / max(image.size)  # Ð·Ð°Ð´Ð°ÐµÐ¼ Ð¼Ð°ÑÑˆÑ‚Ð°Ð± Ð´Ð»Ñ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð°
        size = np.array(image.size) * scale  # Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€
        image = image.resize(size.astype(int), Image.ANTIALIAS)  # Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼

    # Ð•ÑÐ»Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½Ð° Ñ„Ð¾Ñ€Ð¼Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÐµÐ¼, Ð¼ÐµÐ½ÑÐµÐ¼ Ñ„Ð¾Ñ€Ð¼Ñƒ
    if shape:
        image = image.resize(shape, Image.LANCZOS)

    # Ð•ÑÐ»Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹ Ð¼ÐµÑ‚Ð¾Ð´Ñ‹ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ, Ñ‚Ð¾ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ ÐµÐ³Ð¾
    if transform:
        image = transform(image).unsqueeze(0)  # Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð»Ð¸ + Ð²Ñ‹Ñ‚ÑÐ½ÑƒÐ»Ð¸ Ð´Ð¾ Ð±Ð°Ñ‚Ñ‡Ð°

    return image.to(device)


def inference(target, user: UserInfo):
    """Ð¤ÑƒÐ½Ñ†Ð¸Ñ Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ñ„Ð¾Ñ‚Ð¾ Ð¿Ð¾ÑÐ»Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸"""
    inv_normalize = transforms.Normalize(mean=[-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.255],
                                         std=[1 / 0.229, 1 / 0.224, 1 / 0.255])
    inv_content = inv_normalize(target[0])

    styled_img_mp = inv_content.cpu().detach().numpy().transpose(1, 2, 0)
    styled_img_mp[styled_img_mp > 1.] = 1.
    styled_img_mp[styled_img_mp < 0] = 0.

    plt.imshow(styled_img_mp)
    plt.gca().set_axis_off()
    plt.subplots_adjust(top=1, bottom=0, right=1, left=0,
                        hspace=0, wspace=0)
    plt.margins(0, 0)
    plt.savefig(f"{user.directory}\\result_image.png", bbox_inches='tight', pad_inches=0)
    plt.clf()

    return styled_img_mp


@bot.message_handler(commands=['start'])
def send_welcome(message):
    """Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð¿Ñ€Ð¸Ð²ÐµÑÑ‚Ð²Ð¸Ñ Ð¿Ñ€Ð¸ Ð¿ÐµÑ€Ð²Ð¾Ð¼ Ð·Ð°Ð¿ÑƒÑÐºÐµ"""
    global start_markup
    chat_id = message.chat.id
    user = UserInfo(chat_id, False, False, config)
    user_dict.update({user.id: user})
    try:
        os.mkdir(user_dict[chat_id].directory)
    except FileExistsError:
        print('Ð”Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚')
    finally:
        bot.reply_to(message,
                     f'ÐŸÑ€Ð¸Ð²ÐµÑ‚, {message.from_user.first_name}! Ð¯ ÑƒÐ¼ÐµÑŽ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾ Ð¿Ð¾ ÑÑ‚Ð¸Ð»ÑŽ. '
                     'Ð§Ñ‚Ð¾Ð±Ñ‹ Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ, Ð½Ð°Ð¶Ð¼Ð¸ Ð½Ð° ÐºÐ½Ð¾Ð¿ÐºÑƒ ÑÐ½Ð¸Ð·Ñƒ',
                     reply_markup=start_markup)


@bot.message_handler(content_types=['text'])
def bot_message(message):
    if message.text == 'ðŸŽ® ÐÐ°Ñ‡Ð°Ñ‚ÑŒ':
        begin_message(message)

    if message.text == 'ðŸ’¡ ÐžÐ±Ñ‰Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ':
        bot.send_message(chat_id=message.chat.id, text='Ð­Ñ‚Ð¾Ñ‚ Ð±Ð¾Ñ‚ Ð±Ñ‹Ð» Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½ Ð² Ñ€Ð°Ð¼ÐºÐ°Ñ… Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°, '
                                                       'Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿ ÐµÐ³Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð¾Ñ‡ÐµÐ½ÑŒ Ð¿Ñ€Ð¾ÑÑ‚:')
        bot.send_photo(chat_id=message.chat.id, photo=open('photos\\info.jpg', 'rb'), reply_markup=start_markup)

    if message.text == 'âœ… ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾':
        do_style(message)

    if message.text == 'â„¹ï¸ ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾':
        check_photos(message)

    if message.text == '1ï¸âƒ£ Ð¡Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ñ„Ð¾Ñ‚Ð¾':
        change_original_photo(message)

    if message.text == '2ï¸âƒ£ Ð¡Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾ ÑÑ‚Ð¸Ð»Ñ':
        change_style_photo(message)


@bot.message_handler(commands=['begin'])
def begin_message(message):
    bot.reply_to(message, "ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð´Ð²Ð° Ñ„Ð¾Ñ‚Ð¾, ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ, Ð·Ð°Ñ‚ÐµÐ¼ Ñ„Ð¾Ñ‚Ð¾ ÑÑ‚Ð¸Ð»Ñ")


@bot.message_handler(content_types=['photo'])
def photo(message):
    chat_id = int(message.chat.id)
    user = user_dict[chat_id]
    original_photo = user.original_photo
    style_photo = user.style_photo

    fileid = message.photo[-1].file_id
    file_info = bot.get_file(fileid)
    downloaded_file = bot.download_file(file_info.file_path)

    if not original_photo:
        with open(f"{user.directory}\\original_image.jpg", 'wb') as new_file:
            new_file.write(downloaded_file)
            new_file.close()

        user.original_photo = True
        user.content = f"{user.directory}\\original_image.jpg"

        bot.reply_to(message, "ÐžÑ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ñ„Ð¾Ñ‚Ð¾ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾", reply_markup=ready_markup)

        if original_photo and style_photo:
            bot.send_message(chat_id=message.chat.id,
                             text='Ð’ÑÐµ Ñ„Ð¾Ñ‚Ð¾ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹, Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Ð½Ð° ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ ÐºÐ½Ð¾Ð¿ÐºÑƒ,'
                                  ' Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ñ‚Ð¾Ð³Ð¾, Ñ‡Ñ‚Ð¾ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ',
                             reply_markup=ready_markup)

    elif original_photo and not style_photo:
        with open(f"{user.directory}\\style_image.jpg", 'wb') as new_file:
            new_file.write(downloaded_file)
            new_file.close()

        user.style_photo = True
        user.style = f"{user.directory}\\style_image.jpg"

        bot.reply_to(message, "Ð¤Ð¾Ñ‚Ð¾ ÑÑ‚Ð¸Ð»Ñ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾", reply_markup=ready_markup)

        if original_photo and style_photo:
            bot.send_message(chat_id=message.chat.id,
                             text='Ð’ÑÐµ Ñ„Ð¾Ñ‚Ð¾ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹, Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Ð½Ð° ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ ÐºÐ½Ð¾Ð¿ÐºÑƒ,'
                                  ' Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ñ‚Ð¾Ð³Ð¾, Ñ‡Ñ‚Ð¾ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ',
                             reply_markup=ready_markup)

    else:
        bot.send_message(chat_id=message.chat.id,
                         text='Ð’ÑÐµ Ñ„Ð¾Ñ‚Ð¾ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹, Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Ð½Ð° ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ ÐºÐ½Ð¾Ð¿ÐºÑƒ,'
                              ' Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ñ‚Ð¾Ð³Ð¾, Ñ‡Ñ‚Ð¾ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ',
                         reply_markup=ready_markup)

    user_dict.update({user.id: user})


@bot.message_handler(commands=['switch_original'])
def change_original_photo(message):
    """Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ ÑÐ¼ÐµÐ½Ñ‹ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ„Ð¾Ñ‚Ð¾"""
    chat_id = int(message.chat.id)
    user = user_dict[chat_id]

    user.content = 'photos\\ny.jpg'
    user.original_photo = False
    user_dict.update({user.id: user})

    bot.reply_to(message, "Ð”Ð»Ñ ÑÐ¼ÐµÐ½Ñ‹ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ„Ð¾Ñ‚Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ ÐµÐ³Ð¾ ÑÐ½Ð¾Ð²Ð°")


@bot.message_handler(commands=['switch_style'])
def change_style_photo(message):
    """Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ ÑÐ¼ÐµÐ½Ñ‹ Ñ„Ð¾Ñ‚Ð¾ ÑÑ‚Ð¸Ð»Ñ"""
    chat_id = int(message.chat.id)
    user = user_dict[chat_id]

    user.style = 'photos\\Style.jpg'
    user.style_photo = False
    user_dict.update({user.id: user})

    bot.reply_to(message, "Ð”Ð»Ñ ÑÐ¼ÐµÐ½Ñ‹ Ñ„Ð¾Ñ‚Ð¾ ÑÑ‚Ð¸Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ ÐµÐ³Ð¾ ÑÐ½Ð¾Ð²Ð°")


@bot.message_handler(commands=['check'])
def check_photos(message):
    """Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ñ„Ð¾Ñ‚Ð¾"""
    chat_id = int(message.chat.id)
    user = user_dict[chat_id]
    original_photo = user.original_photo
    style_photo = user.style_photo

    if not original_photo and not style_photo:
        bot.reply_to(message, "Ð£ Ð’Ð°Ñ Ð½ÐµÑ‚ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ñ… Ñ„Ð¾Ñ‚Ð¾")

    elif original_photo and not style_photo:
        bot.reply_to(message, "Ð£ Ð’Ð°Ñ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ñ„Ð¾Ñ‚Ð¾")
        bot.send_photo(chat_id=message.chat.id, photo=open(f"{user.directory}\\original_image.jpg", 'rb'))

    elif not original_photo and style_photo:
        bot.reply_to(message, "Ð£ Ð’Ð°Ñ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ„Ð¾Ñ‚Ð¾ ÑÑ‚Ð¸Ð»Ñ:")
        bot.send_photo(chat_id=message.chat.id, photo=open(f"{user.directory}\\style_image.jpg", 'rb'))

    else:
        bot.send_message(chat_id=message.chat.id,
                         text='Ð’ÑÐµ Ñ„Ð¾Ñ‚Ð¾ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹, Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Ð½Ð° ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ ÐºÐ½Ð¾Ð¿ÐºÑƒ,'
                              ' Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ñ‚Ð¾Ð³Ð¾, Ñ‡Ñ‚Ð¾ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ',
                         reply_markup=ready_markup)
        bot.send_message(chat_id=message.chat.id, text='Ð’Ð°ÑˆÐ¸ Ñ„Ð¾Ñ‚Ð¾:')
        bot.send_photo(chat_id=message.chat.id, photo=open(f"{user.directory}\\original_image.jpg", 'rb'))
        bot.send_photo(chat_id=message.chat.id, photo=open(f"{user.directory}\\style_image.jpg", 'rb'))

    user_dict.update({user.id: user})


@bot.message_handler(commands=['do_it'])
def do_style(message):
    """Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ ÐºÐ¾Ð½ÐµÑ‡Ð½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ„Ð¾Ñ‚Ð¾ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ ÐÐ¡"""
    global config
    chat_id = int(message.chat.id)
    user = user_dict[chat_id]
    original_photo = user.original_photo
    style_photo = user.style_photo
    config.content = user.content
    config.style = user.style

    if original_photo and style_photo:
        bot.send_message(chat_id=message.chat.id, text='ÐŸÑ€Ð¸ÑÑ‚ÑƒÐ¿Ð°ÑŽ Ðº Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ñ„Ð¾Ñ‚Ð¾, ÑÑ‚Ð¾ Ð·Ð°Ð¹Ð¼Ñ‘Ñ‚ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ...')

        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.485, 0.456, 0.406),
                                                                                    std=(0.229, 0.224, 0.225))])

        content = load_image(config.content, transform, max_size=config.maxSize)
        style = load_image(config.style, transform, shape=[content.size(3), content.size(2)])
        target = content.clone().requires_grad_(True)

        model = PretrainedNet().eval()  # Ð´Ð»Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð²ÐµÑÐ¾Ð² Ð¿Ñ€ÐµÐ´Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ ÑÐµÑ‚ÐºÐ¸ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ð¸Ð¼ ÐµÐµ Ð² Ñ€ÐµÐ¶Ð¸Ð¼ eval
        optimizer = torch.optim.Adam([target],
                                     lr=0.1)
        content_criteria = nn.MSELoss()

        for step in range(config.totalStep):
            # Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ feature map
            target_features = model.forward(target)
            content_features = model.forward(content)
            style_features = model.forward(style)

            style_loss = 0
            content_loss = 0

            for f1, f2, f3 in zip(target_features, content_features, style_features):
                # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð¿Ð¾Ñ‚ÐµÑ€Ð¸ Ð´Ð»Ñ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»Ð° Ð¸ ÐºÐ¾Ð½ÐµÑ‡Ð½Ð¾Ð¹ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ¸
                content_loss += content_criteria(f1, f2)

                # ÐœÐµÐ½ÑÐµÐ¼ Ñ„Ð¾Ñ€Ð¼Ñƒ ÑÐ²ÐµÑ€Ñ‚Ð¾Ñ‡Ð½Ñ‹Ñ… feature maps. ÐŸÑ€Ð¸Ð²Ð¾Ð´Ð¸Ð¼ Ðº Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ (ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ°Ð½Ð°Ð»Ð¾Ð², ÑˆÐ¸Ñ€Ð¸Ð½Ð°*Ð²Ñ‹ÑÐ¾Ñ‚Ð°)
                _, c, h, w = f1.size()  # Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ batch
                f1 = f1.reshape(c, h * w).to(device)
                f3 = f3.reshape(c, h * w).to(device)

                # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ñƒ Ð“Ñ€Ð°Ð¼Ð° Ð´Ð»Ñ ÐºÐ¾Ð½ÐµÑ‡Ð½Ð¾Ð¹ Ð¸ ÑÑ‚Ð¸Ð»Ñ
                f1 = torch.mm(f1, f1.t())
                f3 = torch.mm(f3, f3.t())

                # ÐŸÐ¾Ñ‚ÐµÑ€Ð¸ Ð´Ð»Ñ ÑÑ‚Ð¸Ð»Ñ Ð¸ ÐºÐ¾Ð½ÐµÑ‡Ð½Ð¾Ð¹ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ¸
                # kf1 = 1 / (4 * (len(f1) * len(f3)) ** 2)
                kf2 = 1 / 4 * (len(f1) * len(f3)) ** 2
                # kf3 = 1 / (c * w * h)
                style_loss += content_criteria(f1, f3) * kf2

            # ÐŸÑ€Ð¾Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð½ÐµÑ‡Ð½ÑƒÑŽ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ Ð¿Ð¾Ñ‚ÐµÑ€ÑŒ
            loss = style_loss + content_loss
            # print(betta)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if (step + 1) % config.step == 0:
                print('Ð¨Ð°Ð³ [{}/{}], ÐžÑˆÐ¸Ð±ÐºÐ° Ð´Ð»Ñ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»Ð°: {:.4f}, ÐžÑˆÐ¸Ð±ÐºÐ° Ð´Ð»Ñ ÑÑ‚Ð¸Ð»Ñ: {}'
                      .format(step + 1, config.totalStep, content_loss.item(), style_loss.item()))

            if (step + 1) % config.sampleStep == 0:  # ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð½Ð°ÑˆÑƒ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÑƒ
                img = target.clone().squeeze()  # ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ð¼ÐµÑÑ‚Ð¾ Ð¿Ð¾Ð´ Ñ‚ÐµÐ½Ð·Ð¾Ñ€
                img = img.clamp_(0, 1)  # Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ, Ð¿Ð¾Ð¿Ð°Ð´Ð°ÑŽÑ‰Ð¸Ðµ Ð² Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½ Ð¼ÐµÐ¶Ð´Ñƒ 0,1
                torchvision.utils.save_image(img, 'output-{}.png'.format(step + 1))

        inference(target, user)

        user.original_photo = False
        user.style_photo = False
        os.remove(f"{user.directory}\\original_image.jpg")
        os.remove(f"{user.directory}\\style_image.jpg")
        user.content = 'photos\\ny.jpg'
        user.style = 'photos\\Style.jpg'

        bot.send_message(chat_id=message.chat.id, text='Ð’Ð°ÑˆÐµ Ñ„Ð¾Ñ‚Ð¾ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾:', reply_markup=start_markup)
        bot.send_photo(chat_id=message.chat.id, photo=open(f"{user.directory}\\result_image.png", 'rb'))
        os.remove(f"{user.directory}\\result_image.png")

    else:
        bot.reply_to(message, 'ÐÐµ Ð²ÑÐµ Ñ„Ð¾Ñ‚Ð¾ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹, Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ "â„¹ï¸ ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾", Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ Ñ„Ð¾Ñ‚Ð¾')

    user_dict.update({user.id: user})


bot.infinity_polling()
